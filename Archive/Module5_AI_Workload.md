# This module pulls together the usage of VM's to deploy a scalable and highly available using Scale and Availability with a simplistic sovereign AI model.

> [!TIP]
> This module has a separate file structure and the document to deploy the workload can be found here [AI Workload](AI_Workload_Folder/Module5_AI_Workload_Guide.md)

```mermaid
flowchart TD
    %% Mobile Client
    Mobile["ðŸ“±  Mobile Device "] --> PublicLB["ðŸŒ  Azure Public Load Balancer "]

    %% Front-end Webservers VMSS
    subgraph FrontEndVMSS["ðŸ–¥ï¸  VM Scale Set Frontend"]
        direction TB
        PublicLB --> VM1["ðŸ§¾  Ubuntu - Apache & PHP"]
        PublicLB --> VM2["ðŸ§¾  Ubuntu - Apache & PHP"]
        PublicLB --> VM3["ðŸ§¾  Ubuntu - Apache & PHP"]
    end

    %% Internal Load Balancer to Database
    FrontEndVMSS --> InternalLB["ðŸ”’  Azure Internal Load Balancer "]

    %% PostgreSQL Availability Set with Replication
    subgraph PGSet["ðŸ—„ï¸  Availability Set - PostgreSQL "]
        direction LR
        subgraph FaultDomain1["ðŸ’¡ Fault Domain 1"]
            VMPrimary["ðŸ“Œ  PostgreSQL Primary"]
        end
        subgraph FaultDomain2["ðŸ’¡ Fault Domain 2"]
            VMReplica["ðŸ“„  PostgreSQL Replica (Streaming)"]
        end
    end

    InternalLB --> VMPrimary
    InternalLB --> VMReplica

    %% AI Model Server
    FrontEndVMSS --> AIModel["ðŸ¤–  AI Model VM (CentOS / AlmaLinux)"]

    %% Data Flow
    VMPrimary -.->|Streaming Replication| VMReplica
```